{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor : Aman Agarwal\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Program to Implement Vector Space Model Document Recommendation\n",
    "\n",
    "'''\n",
    "Name : Aman Agarwal\n",
    "ROLL : 216\n",
    "PRN  : 0120180254\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#IMPORTING ALL REQUIRED LIBRARIES\n",
    "\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#READING INPUT FROM SPECIFIED DOCUMENTS\n",
    "\n",
    "def ReadingFromFile():\n",
    "    \n",
    "    FilesvsLines={}\n",
    "    #List to store the contents of the documents\n",
    "    \n",
    "    NumOfFile=int(input(\"Enter Number Of Files You Will Enter : \"))\n",
    "    \n",
    "    for x in range(0,NumOfFile):    \n",
    "        File=open(\"DOC\" + str(x+1) + \".txt\",'r')\n",
    "        Lines = File.read().splitlines()\n",
    "        FilesvsLines[\"DOC\" + str(x+1)]=Lines\n",
    "        File.close()\n",
    "        \n",
    "    return FilesvsLines,NumOfFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Splitting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SplitWords(Words):\n",
    "    TWords=[]\n",
    "    for Word in Words:\n",
    "        TWords.extend(word_tokenize(Word))\n",
    "    return TWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stop Words using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RemoveStopWords(words):\n",
    "    filtered_sentence = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sentence.append(word.capitalize())\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SplitWords() and RemoveStopWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PreprocessingDocuments():\n",
    "    FilesvsLines,NumOfDocuments=ReadingFromFile()\n",
    "    for key ,value in FilesvsLines.items():\n",
    "        FilesvsLines[key]=RemoveStopWords(SplitWords(value))\n",
    "    return FilesvsLines,NumOfDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Number Of Files You Will Enter : 10\n"
     ]
    }
   ],
   "source": [
    "FilesvsLines,NumOfDocuments=PreprocessingDocuments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing all appeared words using Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Here each word appearing in all of the documents is represented using Vector Space Model, \n",
    "where a vector is assigned to each word, with value of vector elements\n",
    "being 1 if the word appears in the corresponding docuement,\n",
    "and 0 if not. Total number of elements in each vector are equal to the number of documents.\n",
    "'''\n",
    "\n",
    "def create2DArray(FilesvsLines):\n",
    "    array=[]\n",
    "    WordsVSTF={}\n",
    "    for key in FilesvsLines:\n",
    "        for value in FilesvsLines[key]:\n",
    "            array.append(value)\n",
    "    vac=sorted(list(set(array)))\n",
    "    for  x in vac:\n",
    "        for value in FilesvsLines.values():\n",
    "            if(x in value):\n",
    "                if (x in WordsVSTF.keys()):\n",
    "                    WordsVSTF[x].append(1)\n",
    "                else:\n",
    "                    WordsVSTF[x]=[1]\n",
    "            else:\n",
    "                if (x in WordsVSTF.keys()):\n",
    "                    WordsVSTF[x].append(0)\n",
    "                else:\n",
    "                    WordsVSTF[x]=[0]\n",
    "    return WordsVSTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WordsVSTF=create2DArray(FilesvsLines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caluculating TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CalculateIDF(WordsVSTFIDF,NumOfDocuments):\n",
    "    DICTOfIDF = {}\n",
    "    \n",
    "    for key,value in WordsVSTFIDF.items():\n",
    "        sumo = 0\n",
    "        \n",
    "        for x in value:\n",
    "            sumo = sumo + x\n",
    "        # sumo holds the number of docuements a word has occured in\n",
    "        \n",
    "        nsumo = NumOfDocuments/sumo\n",
    "        #nsumo is same as Document Frequency (df)\n",
    "        \n",
    "        idf = math.log10(nsumo)\n",
    "        #Formula for IDF\n",
    "        \n",
    "        DICTOfIDF[key] = idf\n",
    "\n",
    "        value = list(map(lambda x: x*idf,value))\n",
    "        #This anonymous function gives us the TF-IDF by calculating TF*IDF for each term\n",
    "        \n",
    "        WordsVSTFIDF[key]=value\n",
    "        # WordsVSTFIDF holds the TF-IDF values of each word, with the word & TF-IDF vector as key-value pair.\n",
    "        \n",
    "        \n",
    "    return WordsVSTFIDF,DICTOfIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WordsVSTFIDF,DICTOfIDF=CalculateIDF(WordsVSTF,NumOfDocuments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Length of Documents required for Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This basically gives us Document vectors for our documents that\n",
    "# can be used to compare with our Query Docuemnt using Cosine Similarity\n",
    "\n",
    "def CalculateLengthOfDocuments(WordsVSTFIDF,NumOfDocuments):\n",
    "    LengthOfDocuments=[]\n",
    "    for i in range(0,NumOfDocuments):\n",
    "        sumo=0\n",
    "        for values in WordsVSTFIDF.values():\n",
    "            sumo+=math.pow(values[i],2)\n",
    "        LengthOfDocuments.append(math.sqrt(sumo))\n",
    "    return LengthOfDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.471611593372719, 7.67623792542539, 10.164436772134765, 9.045104147642544, 10.361882630360144, 9.490338793740293, 6.651745768713027, 6.407305406470593, 11.922735093549168, 6.186827441386043]\n"
     ]
    }
   ],
   "source": [
    "LengthOfDocuments=CalculateLengthOfDocuments(WordsVSTFIDF,NumOfDocuments)\n",
    "print(LengthOfDocuments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Processing the Query Document by splitting words, removing Stopwords, applying IDF and TF-IDF,\n",
    "# and vectorizing the query\n",
    "\n",
    "def QueryPreprocessing(DICTOfIDF):\n",
    "    Query=[]\n",
    "    QueryVsTFIDF={}\n",
    "    query=input(\"Enter Your Query : \")\n",
    "    queryterm=RemoveStopWords(query.split(\" \"))\n",
    "    listOfIDF=list(DICTOfIDF.keys())\n",
    "    for x in queryterm:\n",
    "        if(x in listOfIDF):\n",
    "            Query.append(x)\n",
    "    print(Query)        \n",
    "    UniqueQuery=sorted(list(set(Query)))\n",
    "    print(UniqueQuery)\n",
    "    for x in UniqueQuery:\n",
    "        idf=DICTOfIDF.get(x)\n",
    "        QueryVsTFIDF[x]=Query.count(x)*idf\n",
    "    sumo=0    \n",
    "    for x in QueryVsTFIDF.values():\n",
    "        sumo+=math.pow(x,2)\n",
    "    LengthOfQuery=math.sqrt(sumo) \n",
    "    return QueryVsTFIDF,LengthOfQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Your Query : Show recipies containing milk\n",
      "['Milk']\n",
      "['Milk']\n"
     ]
    }
   ],
   "source": [
    "QueryVsTFIDF,LengthOfQuery=QueryPreprocessing(DICTOfIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculating Cosine Similarity between the Query Documents and the given Documents\n",
    "\n",
    "def CalculateCosineSimilarity(WordsVSTFIDF,LengthOfDocuments,QueryVsTFIDF,LengthOfQuery,NumOfDocuments):\n",
    "    highVal = 0 \n",
    "    highDoc = 0\n",
    "    reccDoc = []\n",
    "    CosineSimilarity={}\n",
    "    for i in range(0,NumOfDocuments):\n",
    "        sumo=0\n",
    "        for key ,value in QueryVsTFIDF.items():\n",
    "            sumo+=WordsVSTFIDF[key][i]*QueryVsTFIDF[key]\n",
    "            \n",
    "        cos=sumo/(LengthOfDocuments[i]*LengthOfQuery)\n",
    "        if cos > highVal:\n",
    "                highVal = cos\n",
    "                highDoc = \"DOC\"+str(i+1)\n",
    "        if cos > 0.05:\n",
    "                reccDoc.append(\"DOC\"+str(i+1))\n",
    "        CosineSimilarity[\"DOC\"+str(i+1)]=cos\n",
    "    sorted_by_value=sorted(CosineSimilarity.items(), key=lambda CosineSimilarity: CosineSimilarity[1],reverse=True)\n",
    "    \n",
    "    return CosineSimilarity, highDoc, reccDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the recommended Document\n",
    "def printOutput():\n",
    "    print(\"\\n\\nThe reccomended documents are:\", reccDoc)\n",
    "    print (\"\\n\\nDisplaying the most relevent document i.e \", highDoc)\n",
    "    File=open(highDoc + \".txt\",'r')\n",
    "    Lines = File.read()\n",
    "    print(\"\\n\", Lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities of the Query document with the given documents are: \n",
      "\n",
      " {'DOC1': 0.0935500990115709, 'DOC2': 0.0, 'DOC3': 0.0, 'DOC4': 0.0, 'DOC5': 0.0, 'DOC6': 0.0, 'DOC7': 0.0, 'DOC8': 0.10908954076547449, 'DOC9': 0.0, 'DOC10': 0.0}\n",
      "\n",
      "\n",
      "The reccomended documents are: ['DOC1', 'DOC8']\n",
      "\n",
      "\n",
      "Displaying the most relevent document i.e  DOC8\n",
      "\n",
      " Espresso Coffee Recipe\n",
      "\n",
      "Awaken your senses every morning with a refreshing cup of Espresso coffee and kick start your day on a healthy note. Easy to prepare at home, this beverage will surely be a favorite of everyone at your house. You can have this refreshing cup of coffee at anytime of the day with some exotic cookies for better taste. The aroma of this amazing non-alcoholic beverage will surely win hearts of people around you.\n",
      "\n",
      "Read less\n",
      "Ingredients of Espresso Coffee\n",
      "3 cup milk\n",
      "2 teaspoon coffee powder\n",
      "chocolate syrup as required\n",
      "1/2 cup water\n",
      "sugar as required\n",
      "1/4 teaspoon drinking chocolate\n",
      "How to make Espresso Coffee\n",
      "Step 1\n",
      "Add milk to a bowl and boil it on a medium flame.\n",
      "\n",
      "1\n",
      "/ 2\n",
      "previnextes\n",
      "12\n",
      "1/2\n",
      "Step 2\n",
      "Add water, coffee powder and sugar to the blender jar and grind until it forms a foamy liquid.\n",
      "\n",
      "3\n",
      "Step 3\n",
      "Add the coffee-water mix to it when the milk starts boiling and rising upwards .\n",
      "\n",
      "4\n",
      "Step 4\n",
      "Simmer it for a minute and when the boil comes again, remove from the flame. Your frothy espresso coffee is ready.\n",
      "\n",
      "1\n",
      "/ 2\n",
      "previnextes\n",
      "56\n",
      "1/2\n",
      "Step 5\n",
      "Pour into the coffee mugs and sprinkle some chocolate powder.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exception Handling when no mathcing documents are found \n",
    "try:\n",
    "    CosineSimilarity, highDoc, reccDoc = CalculateCosineSimilarity(WordsVSTFIDF,LengthOfDocuments,QueryVsTFIDF,LengthOfQuery,NumOfDocuments)\n",
    "    print(\"Cosine similarities of the Query document with the given documents are: \\n\\n\", CosineSimilarity)\n",
    "    printOutput()\n",
    "    \n",
    "except:\n",
    "     print(\"Sorry, An exception occurred! \\nPlease recheck the query, NO MATCHING DOCUMENTS FOUND\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
